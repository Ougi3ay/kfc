# -*- coding: utf-8 -*-
"""Abstract Base Class

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10sCfA8sM7IZ2nqjyIXiMN-Nprtb9jOgO
"""

"""
BaseKFC: Abstract Base Class for the KFC Procedure
"""

from abc import ABC, abstractmethod
from typing import Dict, List
import numpy as np
from sklearn import clone
from sklearn.base import BaseEstimator
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted

from kfc_model.combiner import BaseCombiner


class BaseKFC(BaseEstimator, ABC):
    """
    Abstract base class for the KFC (K-means, Fitting, Combining) estimator.

    This class handles the core logic:

    This class handles the core logic:
    1. K-Step: Fits one or more clustering models (M partitions).
    2. F-Step: Fits a local estimator to each cluster in each partition.
    3. C-Step: Uses a combiner to aggregate predictions.

    Parameters
    ----------
    local_estimator : estimator object
        The base model to be fitted on each cluster (e.g., LinearRegression).
        This object is cloned for each cluster.

    clusterers : list of clusterer objects
        A list of M clustering algorithms (e.g., [KMeans(n_clusters=5), KMeans(n_clusters=10)]).
        Each clusterer must have `fit` and `predict` methods (like scikit-learn).
        Each clusterer defines one "partition" of the data.

    combiner : BaseCombiner object
        An object that implements the `combine` method (and optionally `combine_proba`)
        to aggregate the M predictions from the M candidate models.
    """

    def __init__(
            self,
            local_estimator: BaseEstimator,
            clusterers: List[BaseEstimator],
            combiner: BaseCombiner
        ):
        self.local_estimator = local_estimator
        self.clusterers = clusterers
        self.combiner = combiner


    @abstractmethod
    def _get_estimator_type(self):
        # This will be 'classifier' or 'regressor'
        pass

    def fit(self, X: np.ndarray, y: np.ndarray) -> "BaseKFC":
        """
        Fits the KFC model.

        1. Fits all M clusterers on X.
        2. For each of the M partitions:
           - Fits K local_estimators, one for each cluster.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            Training data.
        y : array-like of shape (n_samples,)
            Target values.

        Returns
        -------
        self : object
            Returns the instance itself.
        """
        X, y = check_X_y(X, y, accept_sparse=False)

        if not self.clusterers:
            raise ValueError("`clusterers` must be a non-empty list.")

        self.cluster_models_: List[BaseEstimator] = []
        self.fitted_local_models_: List[Dict[int, BaseEstimator]] = []
        self.n_candidates_ = len(self.clusterers)

        # --- Fit each partition ---
        for clusterer in self.clusterers:
            cluster_model, labels = self._fit_clusterer(X, clusterer)
            partition_models = self._fit_local_models(X, y, labels)

            self.cluster_models_.append(cluster_model)
            self.fitted_local_models_.append(partition_models)

        self.is_fitted_ = True
        return self

    # C-Step
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Full KFC prediction (K-Step â†’ F-Step â†’ C-Step).
        
        1. Gets the M predictions from the M candidate models.
        2. (C-Step) Uses the combiner to aggregate them into a final prediction.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
        Data to predict.

        Returns
        -------
        final_predictions : array-like of shape (n_samples,)
        """

        candidate_preds = self._predict_candidates(X)
        return self._combine_predictions(candidate_preds)
    
    # helper function
    # K-Step
    def _fit_clusterer(self, X: np.ndarray, clusterer: BaseEstimator):
        """Fit a clusterer and return fitted model and labels."""
        model = clone(clusterer)
        labels = model.fit_predict(X)
        return model, labels

    # F-Step
    def _fit_local_models(self, X: np.ndarray, y: np.ndarray, labels: np.ndarray) -> Dict[int, BaseEstimator]:
        """Fit a local estimator for each cluster."""
        partition_models: Dict[int, BaseEstimator] = {}

        for k in np.unique(labels):
            mask = labels == k
            if np.sum(mask) == 0:
                continue

            model = clone(self.local_estimator)
            try:
                model.fit(X[mask], y[mask])
                partition_models[k] = model
            except Exception as e:
                print(f"Warning: Skipping cluster {k} due to fit error: {e}")

        return partition_models
    
    def _predict_candidates(self, X: np.ndarray) -> np.ndarray:
        """Predict using all M candidate models."""
        X = check_array(X, ensure_2d=True)
        cluster_labels_list = self._predict_k_step(X)
        return self._predict_f_step(X, cluster_labels_list)
    
    def _predict_k_step(self, X: np.ndarray) -> List[np.ndarray]:
        """Predict cluster labels for all candidate clusterers."""
        check_is_fitted(self, "is_fitted_")
        X = check_array(X, ensure_2d=True)

        return [clusterer.predict(X) for clusterer in self.cluster_models_]

    def _predict_f_step(self, X: np.ndarray, cluster_labels_list: List[np.ndarray]) -> np.ndarray:
        """Predict using fitted local models for each cluster."""
        n_samples = X.shape[0]
        n_candidates = len(cluster_labels_list)
        candidate_preds = np.zeros((n_samples, n_candidates), dtype=np.float32)

        for i, labels in enumerate(cluster_labels_list):
            partition_models = self.fitted_local_models_[i]
            unique_labels = np.array(list(partition_models.keys()))

            # Vectorized assignment per cluster
            for k in unique_labels:
                mask = labels == k
                if np.any(mask):
                    candidate_preds[mask, i] = partition_models[k].predict(X[mask])

            # Fallback for unseen clusters
            unseen_mask = ~np.isin(labels, unique_labels)
            if np.any(unseen_mask):
                candidate_preds[unseen_mask, i] = candidate_preds[:, i].mean()

        return candidate_preds

    def _combine_predictions(self, candidate_preds: np.ndarray) -> np.ndarray:
        """Aggregate candidate predictions using the combiner."""
        return self.combiner.combine(candidate_preds)
